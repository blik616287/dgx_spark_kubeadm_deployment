namespace: graphrag

# -- Embedding model served by Ollama
embedding:
  enabled: true
  image: ollama/ollama:latest
  model: "qwen3-embedding:0.6b"
  port: 11434
  persistence:
    storageClass: longhorn-models
    size: 5Gi
  resources:
    requests:
      cpu: "1"
      memory: 1Gi
    limits:
      cpu: "4"
      memory: 8Gi
      nvidia.com/gpu: "1"

# -- Extraction LLM served by Ollama
extraction:
  enabled: true
  image: ollama/ollama:latest
  model: "qwen3:8b"
  port: 11434
  persistence:
    storageClass: longhorn-models
    size: 10Gi
  resources:
    requests:
      cpu: "1"
      memory: 4Gi
    limits:
      cpu: "4"
      memory: 16Gi
      nvidia.com/gpu: "1"

# -- Reranker model served by vLLM (GPU)
reranker:
  enabled: true
  image: vllm/vllm-openai:nightly-aarch64
  model: "BAAI/bge-reranker-v2-m3"
  port: 8000
  persistence:
    storageClass: longhorn-models
    size: 5Gi
  resources:
    requests:
      cpu: "1"
      memory: 2Gi
    limits:
      cpu: "4"
      memory: 8Gi
      nvidia.com/gpu: "1"

# -- LightRAG application server
lightrag:
  enabled: true
  image: localhost/graphrag-lightrag:v2
  port: 9621
  nodePort: 31436
  # LLM for entity extraction -- points to ollama-extract
  llm:
    binding: ollama
    model: "qwen3:8b-extract"
    host: "http://ollama-extract:11434"
    numCtx: "8192"
  # Embedding -- points to ollama-embed
  embeddingConfig:
    binding: ollama
    model: "qwen3-embedding:0.6b"
    dim: "1024"
    host: "http://ollama-embed:11434"
  # Reranker -- points to vllm-rerank
  rerank:
    enabled: true
    binding: cohere
    model: "BAAI/bge-reranker-v2-m3"
    host: "http://vllm-rerank:8000/rerank"
  # Storage backends
  storage:
    graph: Neo4JStorage
    vector: PGVectorStorage
    kv: PGKVStorage
    docStatus: PGDocStatusStorage
  persistence:
    storageClass: longhorn
    size: 10Gi
  resources:
    requests:
      cpu: "1"
      memory: 512Mi
    limits:
      cpu: "4"
      memory: 4Gi

# -- Neo4j Community Edition
neo4j:
  enabled: true
  image: neo4j:community
  httpPort: 7474
  boltPort: 7687
  nodePort: 31474
  auth:
    username: neo4j
    password: "graphrag-local-2024"
  jvm:
    heapInitial: "1g"
    heapMax: "4g"
    pagecache: "1g"
  persistence:
    storageClass: longhorn
    size: 20Gi
  resources:
    requests:
      cpu: "1"
      memory: 1Gi
    limits:
      cpu: "4"
      memory: 8Gi

# -- PostgreSQL with pgvector
postgresql:
  enabled: true
  image: pgvector/pgvector:pg17
  port: 5432
  auth:
    username: lightrag
    password: "graphrag-local-2024"
    database: lightrag
  persistence:
    storageClass: longhorn
    size: 20Gi
  resources:
    requests:
      cpu: "0.5"
      memory: 256Mi
    limits:
      cpu: "2"
      memory: 2Gi

# -- Code preprocessor (tree-sitter)
codePreprocessor:
  enabled: true
  image: localhost/graphrag-code-preprocessor:v2
  port: 8090
  nodePort: 31490
  resources:
    requests:
      cpu: "0.5"
      memory: 256Mi
    limits:
      cpu: "2"
      memory: 1Gi

# -- Redis (working memory for orchestrator)
redis:
  enabled: true
  image: redis:7-alpine
  port: 6379
  maxmemory: "256mb"
  persistence:
    storageClass: longhorn
    size: 1Gi
  resources:
    requests:
      cpu: "0.1"
      memory: 64Mi
    limits:
      cpu: "1"
      memory: 512Mi

# -- Memory Orchestrator (OpenAI-compatible proxy)
orchestrator:
  enabled: true
  image: localhost/graphrag-orchestrator:latest
  port: 8100
  nodePort: 31800
  sessionTtlSeconds: "7200"
  backends:
    qwen: "http://qwen3-coder-next-predictor.llm-serving.svc.cluster.local:80"
    deepseek: "http://deepseek-r1-distill-32b-predictor.llm-serving.svc.cluster.local:80"
  promoteAfterTurns: "10"
  archivalAfterTurns: "20"
  recallTopK: "3"
  archivalTopK: "3"
  resources:
    requests:
      cpu: "0.5"
      memory: 256Mi
    limits:
      cpu: "2"
      memory: 1Gi

# -- NATS with JetStream (message queue for ingestion)
nats:
  enabled: true
  image: nats:2-alpine
  clientPort: 4222
  monitorPort: 8222
  persistence:
    storageClass: longhorn
    size: 1Gi
  resources:
    requests:
      cpu: "0.1"
      memory: 64Mi
    limits:
      cpu: "1"
      memory: 256Mi

# -- Ingest worker (NATS consumer for async document processing)
ingestWorker:
  enabled: true
  image: localhost/graphrag-ingest-worker:latest
  replicas: 1
  maxRedeliveries: "3"
  ackWaitSeconds: "600"
  batchSize: "20"
  resources:
    requests:
      cpu: "0.25"
      memory: 128Mi
    limits:
      cpu: "1"
      memory: 512Mi

nodeSelector:
  kubernetes.io/arch: arm64
