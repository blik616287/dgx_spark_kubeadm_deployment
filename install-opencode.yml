---
- name: Install OpenCode and configure for local LLM inference
  hosts: k8s
  become: true
  vars:
    local_user: "{{ ansible_env.SUDO_USER | default('b') }}"
    kubeconfig: "/home/{{ ansible_env.SUDO_USER | default('b') }}/.kube/config"
    opencode_config_dir: "/home/{{ ansible_env.SUDO_USER | default('b') }}/.config/opencode"
    # NodePort assignments for accessing Ollama from the host
    qwen_nodeport: 31434
    deepseek_nodeport: 31435

  environment:
    KUBECONFIG: "{{ kubeconfig }}"

  tasks:
    # ── Install OpenCode ─────────────────────────────────────────
    - name: Check if opencode is installed
      become: true
      become_user: "{{ local_user }}"
      shell: "PATH=$HOME/.opencode/bin:$PATH which opencode"
      register: opencode_check
      failed_when: false
      changed_when: false

    - name: Install opencode from opencode.ai
      become: true
      become_user: "{{ local_user }}"
      shell: curl -fsSL https://opencode.ai/install | bash
      when: opencode_check.rc != 0

    - name: Add opencode to PATH in shell profile
      become: true
      become_user: "{{ local_user }}"
      lineinfile:
        path: "/home/{{ local_user }}/.profile"
        line: 'export PATH="$HOME/.opencode/bin:$PATH"'
        create: true

    - name: Verify opencode installed
      become: true
      become_user: "{{ local_user }}"
      shell: "$HOME/.opencode/bin/opencode -v"
      register: opencode_version
      changed_when: false

    - name: Show opencode version
      debug:
        msg: "{{ opencode_version.stdout }}"

    # ── Expose models via NodePort ───────────────────────────────
    - name: Create NodePort service for Qwen3-Coder-Next
      become: true
      become_user: "{{ local_user }}"
      shell: |
        cat <<'EOF' | kubectl apply -f -
        apiVersion: v1
        kind: Service
        metadata:
          name: qwen3-coder-next-nodeport
          namespace: llm-serving
        spec:
          type: NodePort
          selector:
            app: isvc.qwen3-coder-next-predictor
          ports:
            - port: 11434
              targetPort: 11434
              nodePort: {{ qwen_nodeport }}
        EOF

    - name: Create NodePort service for DeepSeek-R1
      become: true
      become_user: "{{ local_user }}"
      shell: |
        cat <<'EOF' | kubectl apply -f -
        apiVersion: v1
        kind: Service
        metadata:
          name: deepseek-r1-distill-32b-nodeport
          namespace: llm-serving
        spec:
          type: NodePort
          selector:
            app: isvc.deepseek-r1-distill-32b-predictor
          ports:
            - port: 11434
              targetPort: 11434
              nodePort: {{ deepseek_nodeport }}
        EOF

    - name: Verify NodePort services
      become: true
      become_user: "{{ local_user }}"
      shell: kubectl get svc -n llm-serving qwen3-coder-next-nodeport deepseek-r1-distill-32b-nodeport
      register: nodeport_svcs
      changed_when: false

    - name: Show NodePort services
      debug:
        var: nodeport_svcs.stdout_lines

    # ── Configure OpenCode ───────────────────────────────────────
    - name: Create opencode config directory
      file:
        path: "{{ opencode_config_dir }}"
        state: directory
        owner: "{{ local_user }}"
        mode: '0755'

    - name: Write opencode config
      copy:
        dest: "{{ opencode_config_dir }}/opencode.json"
        owner: "{{ local_user }}"
        mode: '0644'
        content: |
          {
            "$schema": "https://opencode.ai/config.json",
            "model": "qwen/qwen3-coder-next:q4_K_M",
            "small_model": "deepseek/deepseek-r1-distill-32b-tools",
            "provider": {
              "qwen": {
                "npm": "@ai-sdk/openai-compatible",
                "name": "Qwen3 Coder Next (local)",
                "options": {
                  "baseURL": "http://localhost:{{ qwen_nodeport }}/v1"
                },
                "models": {
                  "qwen3-coder-next:q4_K_M": {
                    "name": "Qwen3 Coder Next Q4_K_M",
                    "limit": {
                      "context": 131072,
                      "output": 32768
                    }
                  }
                }
              },
              "deepseek": {
                "npm": "@ai-sdk/openai-compatible",
                "name": "DeepSeek R1 Distill 32B (local)",
                "options": {
                  "baseURL": "http://localhost:{{ deepseek_nodeport }}/v1"
                },
                "models": {
                  "deepseek-r1-distill-32b-tools": {
                    "name": "DeepSeek R1 Distill Qwen 32B Q4_K_M (tools)",
                    "limit": {
                      "context": 32768,
                      "output": 8192
                    }
                  }
                }
              }
            }
          }

    - name: Show setup summary
      debug:
        msg:
          - "OpenCode installed and configured"
          - "Default model: Qwen3 Coder Next (code generation) at localhost:{{ qwen_nodeport }}"
          - "Small model: DeepSeek R1 Distill 32B (reasoning) at localhost:{{ deepseek_nodeport }}"
          - "Config: {{ opencode_config_dir }}/opencode.json"
          - "Run 'opencode' to start"
