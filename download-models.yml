---
- name: Download LLM models into Longhorn PVCs
  hosts: k8s
  become: true
  vars:
    local_user: "{{ ansible_env.SUDO_USER | default('b') }}"
    kubeconfig: "/home/{{ local_user }}/.kube/config"
    ollama_models:
      - name: qwen3-coder-next
        tag: "qwen3-coder-next:q4_K_M"
        namespace: llm-serving
        helm_release: llm-serving
        pvc: ollama-qwen3-coder-next
        size: 60Gi
      - name: deepseek-r1-distill-32b
        tag: "deepseek-r1:32b"
        namespace: llm-serving
        helm_release: llm-serving
        pvc: ollama-deepseek-r1-distill-32b
        size: 30Gi
      - name: qwen3-embedding
        tag: "qwen3-embedding:0.6b"
        namespace: graphrag
        helm_release: graphrag
        pvc: ollama-embed-data
        size: 5Gi
      - name: llama3.1-8b
        tag: "llama3.1:8b"
        namespace: graphrag
        helm_release: graphrag
        pvc: ollama-extract-data
        size: 10Gi
    huggingface_models:
      - name: bge-reranker-v2-m3
        repo: "BAAI/bge-reranker-v2-m3"
        namespace: graphrag
        helm_release: graphrag
        pvc: vllm-rerank-data
        size: 5Gi

  environment:
    KUBECONFIG: "{{ kubeconfig }}"

  tasks:
    # ── Create namespaces and PVCs ───────────────────────────────
    - name: Ensure namespaces exist
      become: true
      become_user: "{{ local_user }}"
      shell: kubectl create namespace {{ item }} --dry-run=client -o yaml | kubectl apply -f -
      loop:
        - llm-serving
        - graphrag

    - name: Create Ollama model PVCs
      become: true
      become_user: "{{ local_user }}"
      shell: |
        cat <<'EOF' | kubectl apply -f -
        apiVersion: v1
        kind: PersistentVolumeClaim
        metadata:
          name: {{ item.pvc }}
          namespace: {{ item.namespace }}
          labels:
            app.kubernetes.io/managed-by: Helm
          annotations:
            meta.helm.sh/release-name: {{ item.helm_release }}
            meta.helm.sh/release-namespace: {{ item.namespace }}
        spec:
          accessModes: ["ReadWriteOnce"]
          storageClassName: longhorn-models
          resources:
            requests:
              storage: {{ item.size }}
        EOF
      loop: "{{ ollama_models }}"

    - name: Create HuggingFace model PVCs
      become: true
      become_user: "{{ local_user }}"
      shell: |
        cat <<'EOF' | kubectl apply -f -
        apiVersion: v1
        kind: PersistentVolumeClaim
        metadata:
          name: {{ item.pvc }}
          namespace: {{ item.namespace }}
          labels:
            app.kubernetes.io/managed-by: Helm
          annotations:
            meta.helm.sh/release-name: {{ item.helm_release }}
            meta.helm.sh/release-namespace: {{ item.namespace }}
        spec:
          accessModes: ["ReadWriteOnce"]
          storageClassName: longhorn-models
          resources:
            requests:
              storage: {{ item.size }}
        EOF
      loop: "{{ huggingface_models }}"

    - name: Wait for PVCs to be bound
      become: true
      become_user: "{{ local_user }}"
      shell: kubectl -n {{ item.namespace }} wait --for=jsonpath='{.status.phase}'=Bound pvc/{{ item.pvc }} --timeout=120s
      loop: "{{ ollama_models + huggingface_models }}"

    # ── Check existing Ollama models ─────────────────────────────
    - name: Check Ollama model integrity in PVCs
      become: true
      become_user: "{{ local_user }}"
      command: >
        kubectl run check-{{ item.name }} --rm -i --restart=Never
        -n {{ item.namespace }}
        --image=busybox:latest
        --overrides='{"spec":{"volumes":[{"name":"data","persistentVolumeClaim":{"claimName":"{{ item.pvc }}"}}],"containers":[{"name":"check","image":"busybox:latest","command":["sh","-c","if find /data/manifests -type f 2>/dev/null | grep -q .; then partials=$(find /data/blobs -name *-partial* 2>/dev/null | wc -l); if [ $partials -gt 0 ]; then echo incomplete; else echo ok; fi; else echo missing; fi"],"volumeMounts":[{"name":"data","mountPath":"/data"}]}]}}'
      loop: "{{ ollama_models }}"
      register: ollama_check
      changed_when: false
      timeout: 120

    # ── Pull missing Ollama models ───────────────────────────────
    - name: Pull missing or incomplete Ollama models
      become: true
      become_user: "{{ local_user }}"
      command: >
        kubectl run ollama-pull-{{ item.item.name }} --rm -i --restart=Never
        -n {{ item.item.namespace }}
        --image=ollama/ollama:latest
        --overrides='{"spec":{"volumes":[{"name":"data","persistentVolumeClaim":{"claimName":"{{ item.item.pvc }}"}}],"containers":[{"name":"pull","image":"ollama/ollama:latest","env":[{"name":"OLLAMA_MODELS","value":"/root/.ollama"}],"command":["sh","-c","ollama serve & sleep 3 && ollama pull {{ item.item.tag }} && echo PULL_COMPLETE"],"volumeMounts":[{"name":"data","mountPath":"/root/.ollama"}]}]}}'
      loop: "{{ ollama_check.results }}"
      when: item.stdout is not defined or item.stdout.strip() != "ok"
      register: ollama_pull
      changed_when: ollama_pull.stdout is defined and 'PULL_COMPLETE' in ollama_pull.stdout
      timeout: 3600

    # ── Verify Ollama SHA256 checksums ───────────────────────────
    - name: Verify Ollama model SHA256 checksums
      become: true
      become_user: "{{ local_user }}"
      command: >
        kubectl run verify-{{ item.name }} --rm -i --restart=Never
        -n {{ item.namespace }}
        --image=busybox:latest
        --overrides='{"spec":{"volumes":[{"name":"data","persistentVolumeClaim":{"claimName":"{{ item.pvc }}"}}],"containers":[{"name":"verify","image":"busybox:latest","command":["sh","-c","manifest=$(find /data/manifests -type f 2>/dev/null | head -1); if [ -z \"$manifest\" ]; then echo SKIP; exit 0; fi; failed=0; for digest in $(grep -oE sha256:[a-f0-9]+ \"$manifest\"); do blob=/data/blobs/$(echo $digest | tr : -); expected=$(echo $digest | cut -d: -f2); if [ ! -f \"$blob\" ]; then echo FAIL:missing:$digest; failed=1; continue; fi; actual=$(sha256sum \"$blob\" | cut -d\" \" -f1); size=$(du -h \"$blob\" | cut -f1); if [ \"$actual\" = \"$expected\" ]; then echo PASS:$size:$digest; else echo FAIL:$size:$digest; failed=1; fi; done; exit $failed"],"volumeMounts":[{"name":"data","mountPath":"/data"}]}]}}'
      loop: "{{ ollama_models }}"
      register: ollama_verify
      timeout: 600

    - name: Show Ollama checksum results
      debug:
        msg: "{{ item.item.name }}: {{ item.stdout }}"
      loop: "{{ ollama_verify.results }}"

    # ── Check existing HuggingFace models ────────────────────────
    - name: Check HuggingFace model integrity in PVCs
      become: true
      become_user: "{{ local_user }}"
      command: >
        kubectl run check-hf-{{ item.name }} --rm -i --restart=Never
        -n {{ item.namespace }}
        --image=busybox:latest
        --overrides='{"spec":{"volumes":[{"name":"data","persistentVolumeClaim":{"claimName":"{{ item.pvc }}"}}],"containers":[{"name":"check","image":"busybox:latest","command":["sh","-c","if [ -f /data/config.json ]; then incomplete=$(find /data -name *.incomplete 2>/dev/null | wc -l); if [ $incomplete -gt 0 ]; then echo incomplete; else echo ok; fi; else echo missing; fi"],"volumeMounts":[{"name":"data","mountPath":"/data"}]}]}}'
      loop: "{{ huggingface_models }}"
      register: hf_check
      changed_when: false
      timeout: 120

    # ── Download missing HuggingFace models ──────────────────────
    - name: Download missing HuggingFace models
      become: true
      become_user: "{{ local_user }}"
      command: >
        kubectl run hf-pull-{{ item.item.name }} --rm -i --restart=Never
        -n {{ item.item.namespace }}
        --image=python:3.12-slim
        --overrides='{"spec":{"volumes":[{"name":"data","persistentVolumeClaim":{"claimName":"{{ item.item.pvc }}"}}],"containers":[{"name":"pull","image":"python:3.12-slim","command":["sh","-c","pip install -q huggingface_hub hf_transfer && HF_HUB_ENABLE_HF_TRANSFER=1 python3 -c \"from huggingface_hub import snapshot_download; snapshot_download('"'"'{{ item.item.repo }}'"'"', local_dir='"'"'/data'"'"'); print('"'"'HF_PULL_COMPLETE'"'"')\""],"volumeMounts":[{"name":"data","mountPath":"/data"}]}]}}'
      loop: "{{ hf_check.results }}"
      when: item.stdout is not defined or item.stdout.strip() != "ok"
      register: hf_pull
      changed_when: hf_pull.stdout is defined and 'HF_PULL_COMPLETE' in hf_pull.stdout
      timeout: 1800

    # ── Verify HuggingFace integrity ─────────────────────────────
    - name: Verify HuggingFace model integrity
      become: true
      become_user: "{{ local_user }}"
      command: >
        kubectl run verify-hf-{{ item.name }} --rm -i --restart=Never
        -n {{ item.namespace }}
        --image=busybox:latest
        --overrides='{"spec":{"volumes":[{"name":"data","persistentVolumeClaim":{"claimName":"{{ item.pvc }}"}}],"containers":[{"name":"verify","image":"busybox:latest","command":["sh","-c","if [ ! -f /data/config.json ]; then echo SKIP; exit 0; fi; incomplete=$(find /data -name *.incomplete 2>/dev/null | wc -l); if [ $incomplete -gt 0 ]; then echo FAIL:incomplete; exit 1; fi; for sf in /data/*.safetensors; do [ -f \"$sf\" ] || continue; size=$(du -h \"$sf\" | cut -f1); hash=$(sha256sum \"$sf\" | cut -d\" \" -f1); echo PASS:$size:$(basename $sf):sha256:$hash; done; echo ok"],"volumeMounts":[{"name":"data","mountPath":"/data"}]}]}}'
      loop: "{{ huggingface_models }}"
      register: hf_verify
      timeout: 600

    - name: Show HuggingFace checksum results
      debug:
        msg: "{{ item.item.name }}: {{ item.stdout }}"
      loop: "{{ hf_verify.results }}"

    # ── Summary ──────────────────────────────────────────────────
    - name: Show PVC status
      become: true
      become_user: "{{ local_user }}"
      shell: |
        echo "=== Model PVCs ==="
        kubectl get pvc -n llm-serving --no-headers 2>/dev/null || echo "  (none)"
        echo ""
        kubectl get pvc -n graphrag --no-headers 2>/dev/null || echo "  (none)"
      register: pvc_status

    - name: Display PVC status
      debug:
        var: pvc_status.stdout_lines
